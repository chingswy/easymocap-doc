<!--
 * @Date: 2021-04-07 10:27:04
 * @Author: Qing Shuai
 * @LastEditors: Qing Shuai
 * @LastEditTime: 2021-07-07 11:47:55
 * @FilePath: /Dataset-Demo/index.html
-->
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ZJU-MoCap</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <style>
        table {
            /* width: 710px; */
            margin: 10px auto;
            border-collapse: collapse;
            text-align: center;
        }

        td,
        th {
            border: 1px solid #333;
        }

        thead tr {
            height: 40px;
            background-color: #ccc;
        }
    </style>
</head>

<body>
    <!-- cover -->
    <section>
        <div class="jumbotron text-center mt-4">
            <div class="container">
                <div class="row">
                    <div class="col-12">
                        <!-- <img class="img-fluid" src="images/logo.jpg" alt="MHlogo" width="100"> -->
                        <h1>ZJU-MoCap Dataset</h1>
                        <p>State Key Lab of CAD & CG, Zhejiang University &nbsp;&nbsp;</p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- abstract -->
    <section>
        <div class="container">
            <div class="row">
                <div class="col-12 text-center">
                    <h1>LightStage</h1>
                    <hr style="margin-top:0px">
                    <p class="text-left">LightStage is a multi-view dataset, which is proposed in NeuralBody. This dataset captures multiple dynamic human videos using a multi-camera system that has 20+ synchronized cameras. The humans perform complex motions, including twirling, Taichi, arm swings, warmup, punching, and kicking. We provide the SMPL-X parameters recovered with EasyMocap, which contain the motions of body, hand and face.</p>
                </div>
            </div>
        </div>
    </section>
    <br>

    <section>
        <div class="container">
            <div class="row">
                <div class="col-12 text-center">
                    <div class="row justify-content-center">
                        <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" onclick="previousPage('lightstage')"
                                style="margin-top:10px" role="button">
                                Prev
                            </p>
                            </p>
                        </div>
                        <div class="column">
                            <p class="mb-5">
                            <p id="page-number-lightstage" class="btn btn-large btn-light" style="margin-top:10px"
                                role="button">1</p>
                            </p>
                        </div>
                        <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" onclick="nextPage('lightstage')" style="margin-top:10px"
                                role="button">Next</p>
                            </p>
                        </div>
<!--                         <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" style="margin-top:10px"
                                role="button"><a href="https://zjueducn-my.sharepoint.com/:f:/g/personal/s_q_zju_edu_cn/Ele6OHFqNZVLoMap8Jt732EBHvz9BaDWQ2OGISzrb32M6w?e=RdYvb1">Data</a></p>
                            </p>
                        </div> -->
                    </div>
                    <hr style="margin-top:-15px">

                    <table cellspacing="0">
                        <thead>
                        </thead>
                        <tbody id="tab-lightstage">
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <!-- Mirrored Human -->
    
    <!-- abstract -->
    <section>
        <div class="container">
            <div class="row">
                <div class="col-12 text-center">
                    <h1>Mirrored-Human</h1>
                    <hr style="margin-top:0px">
                    <p class="text-left">"Mirrored-Human"  is a large-scale Internet dataset containing videos in which we can see the person and the person's image through a mirror, together with pseudo ground-truth annotations generated by our optimization-based framework.
                    <br>
                        The dataset includes:
                    <br>
                        - video clips (1500k+ frames). <br>
                        - 2D human keypoints. <br>
                        - 3D poses (SMPL model parameters) obtained with our method. Our method leverages an additional view provided by the mirror reflection so as to resolve the depth ambiguity. <br>
                        
                        Here are some sample data:</p>
                </div>
            </div>
        </div>
    </section>
    <br>

    <section>
        <div class="container">
            <div class="row">
                <div class="col-12 text-center">
                    <hr style="margin-top:0px">
                    <div class="row justify-content-center">
                        <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" onclick="previousPage('mirror')" style="margin-top:10px"
                                role="button">
                                Prev
                            </p>
                            </p>
                        </div>
                        <div class="column">
                            <p class="mb-5">
                            <p id="page-number-mirror" class="btn btn-large btn-light" style="margin-top:10px"
                                role="button">1</p>
                            </p>
                        </div>
                        <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" onclick="nextPage('mirror')" style="margin-top:10px"
                                role="button">Next</p>
                            </p>
                        </div>
<!--                         <div class="column">
                            <p class="mb-5">
                            <p class="btn btn-large btn-light" style="margin-top:10px"
                                role="button"><a href="https://zjueducn-my.sharepoint.com/:f:/g/personal/s_q_zju_edu_cn/Ev_AEe3x13JAq-dpDhp6i-gBDKlK79koxfQRbka-bcDNAA?e=IFLzH0">Data</a></p>
                            </p> -->
                        </div>
                    </div>
                    <hr style="margin-top:-15px">

                    <table cellspacing="0">
                        <thead>
                        </thead>
                        <tbody id="tab-mirror">
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <section>
        <div class="container">
            <div class="row ">
              <div class="col-12">
                  <h3>Citation</h3>
                  <hr style="margin-top:0px">
                  <p>
                    Please cite the corresponding paper if you use this dataset.
                </p>
                      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
        <code>
    @inproceedings{peng2021neural,
        title={Neural Body: Implicit Neural Representations with Structured Latent Codes for Novel View Synthesis of Dynamic Humans},
        author={Peng, Sida and Zhang, Yuanqing and Xu, Yinghao and Wang, Qianqian and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
        booktitle={CVPR},
        year={2021}
    }
    </code>
    <code>
    @inproceedings{fang2021mirrored,
        title={Reconstructing 3D Human Pose by Watching Humans in the Mirror},
        author={Fang, Qi and Shuai, Qing and Dong, Junting and Bao, Hujun and Zhou, Xiaowei},
        booktitle={CVPR},
        year={2021}
    }
    </code>
    </pre>
                  <hr>
              </div>
            </div>
        </div>

    </section>

    <script>
        var infos = {
            "mirror": {
                "root": "./mirror-all/",
                "start": 0,
                "seqs": ['DeoC3ZNN79E+000020+000090.mp4', 'r_CRMeOqQtA+000070+000122.mp4', 'AVCtTdubVUc+000070+000190.mp4', 'kvNTiBSffaI+000110+000190.mp4', 'l0oG4W2nRDk+000110+000170.mp4', 'Zxs1QNmjQ50+000050+000220.mp4', 'BtrTAQkdYMs+000040+000100.mp4', '87EtqKMate8+000040+000150.mp4', '_zo9fbuqI9w+000040+000130.mp4', 'sLFVOvKX0a0+000109+000249.mp4', 'EzIYrAotSeQ+000040+000080.mp4', 'vRYf25I6uYo+000060+000100.mp4', '9IpWjz8pg6w+000660+001127.mp4', '0junSQuSJh4+013000+013970.mp4', '4_oQ8YTWg-I+000170+001910.mp4', 'cxjV5uFQ1E8+000000+001580.mp4', 'cYnGzlbqics+001300+001570.mp4', '9sJtld8Ig8Q+000240+002060.mp4', '2P2nIhNTZgU+001513+002233.mp4', 'EfuexXsdqmY+000000+001250.mp4', 'bSZtOc-sjSs+012180+013280.mp4', 'B3Q1PbYdiDc+000790+001530.mp4', 'iElFpFzlSwE+008170+009070.mp4', 'gRaNn2azYYk+000740+002290.mp4', 'M2Y6CDnKnWw+004550+005660.mp4', 'C4hx7Sb_RN0+001030+001450.mp4', 'r51-3izUKG0+000100+000920.mp4', 'kqAvo_dQ-_0+002350+003102.mp4', '1WJtsn8MvAY+000090+002287.mp4', '8QfzSXJrdGc+010290+011240.mp4', 'onW3bjuR1z0+000033+000863.mp4', 'SrclajF1Ucs+036150+038150.mp4', 'gm1YgI0UXsk+002350+003170.mp4', 'ilItUNfCmQs+012340+013230.mp4', 'XB-SAiswJRk+018264+019324.mp4', 'xMhvz3QuObM+000040+000730.mp4', '8xFhcUChyTE+011800+013040.mp4', 'c5CSX4f0boA+002080+002610.mp4', 'ezgoIwfz-m8+007360+008370.mp4', '6UUpPNtGRJI+002290+002970.mp4', '1-9KMA4OZSk+012450+013070.mp4', 'G1ttpB05_UY+003133+003754.mp4', 'X2X5zUfge5c+000100+001670.mp4', '8QtfqQb6Pt8+010050+012920.mp4', 'mFCWW13CfqI+001120+001950.mp4', 'IXZjtfckhPg+004900+005881.mp4', 'lpkbFWo8GD0+002640+003390.mp4', '8Nlf5p1fnos+010202+011732.mp4', 'CE8tDfMbA7M+010040+010830.mp4', 'BHxrLHmhcLE+006690+007920.mp4', 'kHQhB8POuYc+000090+000771.mp4', 'IG2VQJYXplM+012790+013930.mp4', 'kC4I9MOxjfQ+000740+001340.mp4', 'hVDPS-f6K5o+002880+003470.mp4', 'xwgefd1_csA+000070+001440.mp4'],
                "rows": 2,
                "cols": 4,
                "width": 250,
            },
            "lightstage": {
                "root": "./LightStage/",
                "start": 0,
                "seqs": ['ls-363-smplx-concat.mp4', 'ls-364-smplx-concat.mp4', 'ls-365-smplx-concat.mp4', 'ls-366-smplx-concat.mp4', 'ls-367-smplx-concat.mp4', 'ls-368-smplx-concat.mp4', 'ls-369-smplx-concat.mp4', 'ls-370-smplx-concat.mp4', 'ls-371-smplx-concat.mp4', 'ls-377-smplx-concat.mp4', 'ls-378-smplx-concat.mp4', 'ls-379-smplx-concat.mp4', 'ls-380-smplx-concat.mp4', 'ls-381-smplx-concat.mp4', 'ls-382-smplx-concat.mp4', 'ls-383-smplx-concat.mp4', 'ls-384-smplx-concat.mp4', 'ls-385-smplx-concat.mp4', 'ls-386-smplx-concat.mp4', 'ls-387-smplx-concat.mp4', 'ls-388-smplx-concat.mp4', 'ls-389-smplx-concat.mp4', 'ls-390-smplx-concat.mp4', 'ls-392-smplx-concat.mp4', 'ls-393-smplx-concat.mp4', 'ls-394-smplx-concat.mp4', 'ls-395-smplx-concat.mp4'],
                "rows": 2,
                "cols": 2,
                "width": 500,
            }
        };

        function get_seqname(seqname) {
            var names = seqname.split("/");
            if (names.length > 1) {
                seq = names[1].substring(0, 11)
            } else {
                seq = names[0].substring(0, 11)
            }
            return seq;
        }

        function reloadPage(dataset) {
            var inputs = document.getElementsByClassName("video-output-" + dataset);
            for (var r = 0; r < infos[dataset]["rows"]; r++) {
                for (var c = 0; c < infos[dataset]["cols"]; c++) {
                    var i = r * infos[dataset]["cols"] + c + infos[dataset]["start"];
                    var td = inputs[r * infos[dataset]["cols"] + c];
                    if (i >= infos[dataset]["seqs"].length) {
                        td.src = "";
                        continue;
                    } else {
                        // td.parentNode.parentNode.href = "https://www.youtube.com/watch?v=" + get_seqname(seqs[i]);
                        td.src = infos[dataset]["root"] + infos[dataset]["seqs"][i];
                    }
                    td.parentNode.load();
                    td.parentNode.play();
                }
            }
            var page = document.getElementById("page-number-" + dataset);
            page.innerText = 1 + infos[dataset]["start"] / (infos[dataset]["cols"] * infos[dataset]["rows"]);
        }

        function previousPage(dataset) {
            if (infos[dataset]['start'] == 0) return;
            var videos_page = infos[dataset]['rows'] * infos[dataset]['cols'];
            infos[dataset]['start'] = Math.max(infos[dataset]['start'] - videos_page, 0);
            reloadPage(dataset);
        }

        function nextPage(dataset) {
            var videos_page = infos[dataset]['rows'] * infos[dataset]['cols'];
            var start = infos[dataset]['start'];
            if (start + videos_page >= infos[dataset]['seqs'].length) return;
            start = Math.min(start + videos_page, infos[dataset]['seqs'].length);
            infos[dataset]['start'] = start;
            reloadPage(dataset);
        }

        function add_dataset(dataset, info) {
            var table = document.getElementById("tab-" + dataset);
            for (var r = 0; r < info["rows"]; r++) {
                var tr = document.createElement('tr');
                table.appendChild(tr);
                for (var c = 0; c < info["cols"]; c++) {
                    var i = r * info["cols"] + c + info["start"];
                    var td = document.createElement('td');
                    td.width = info["width"];
                    var link = document.createElement('a');
                    var filename = info["root"] + info["seqs"][i];
                    link.innerHTML = '<video width="' + info["width"] + '" playsinline="" autoplay="autoplay" loop="loop" preload="" muted=""><source src="' + filename + '" type="video/mp4"' + ' class="video-output-' + dataset + '"' + '></video>';
                    td.appendChild(link);
                    tr.appendChild(td);
                }
            }
        }

        for (var dataset in infos) {
            var info = infos[dataset];
            add_dataset(dataset, info);
        }
    </script>
</body>

</html>
